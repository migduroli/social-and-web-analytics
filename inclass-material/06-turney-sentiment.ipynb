{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3272424e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import nltk\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "from enum import Enum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "27cae3bb",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "class PennTreebank(Enum):\n",
    "    CC = 1 # Coordinating conjunction\n",
    "    CD = 2 # Cardinal number\n",
    "    DT = 3 # Determiner\n",
    "    EX = 4 # Existential there\n",
    "    FW = 5 # Foreign word\n",
    "    IN = 6 # Preposition or subordinating conjunction\n",
    "    JJ = 7 # Adjective\n",
    "    JJR = 8 # Adjective, comparative\n",
    "    JJS = 9 # Adjective, superlative\n",
    "    LS = 10 # List item marker\n",
    "    MD = 11 # Modal\n",
    "    NN = 12 # Noun, singular or mass\n",
    "    NNS = 13 # Noun, plural\n",
    "    NNP = 14 # Proper noun, singular\n",
    "    NNPS = 15 # Proper noun, plural\n",
    "    PDT = 16 # Predeterminer\n",
    "    POS = 17 # Possessive ending\n",
    "    PRP = 18 # Personal pronoun\n",
    "    # PRP$ = 19 # Possessive pronoun\n",
    "    RB = 20 # Adverb\n",
    "    RBR = 21 # Adverb, comparative\n",
    "    RBS = 22 # Adverb, superlative\n",
    "    RP = 23 # Particle\n",
    "    SYM = 24 # Symbol\n",
    "    TO = 25 # to\n",
    "    UH = 26 # Interjection\n",
    "    VB = 27 # Verb, base form\n",
    "    VBD = 28 # Verb, past tense\n",
    "    VBG = 29 # Verb, gerund or present participle\n",
    "    VBN = 30 # Verb, past participle\n",
    "    VBP = 31 # Verb, non-3rd person singular present\n",
    "    VBZ = 32 # Verb, 3rd person singular present\n",
    "    WDT = 33 # Wh-determiner\n",
    "    WP = 34 # Wh-pronoun\n",
    "    # WP$ = 35 # Possessive wh-pronoun\n",
    "    WRB = 36 # Wh-adverb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9d9801f6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def read_document(filename: str) -> str:\n",
    "    \"\"\"Reads text from file with name: filename\n",
    "    \"\"\"\n",
    "    with open(filename, \"r\", encoding=\"utf8\") as file:\n",
    "        return file.read()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2374b7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_train_test_per_fold(\n",
    "        datasets: list,\n",
    "        classes: str,\n",
    "        data_path: str,\n",
    "        filenames: list,\n",
    "        fold: int,\n",
    "        max_train_files: int = None,\n",
    "        max_test_files: int = None,\n",
    ") -> list:\n",
    "    \"\"\"Prepares the train-test split of the files to be used later\n",
    "    \"\"\"\n",
    "    trains = {c: [] for c in classes}\n",
    "    tests = {c: [] for c in classes}\n",
    "    \n",
    "    for c in classes:\n",
    "        for filename in filenames[c]:\n",
    "            file_path = f\"{data_path}/{c}/{filename}\"\n",
    "            if filename[2] == str(fold):\n",
    "                tests[c].append(file_path)\n",
    "                trains[c].append(file_path)\n",
    "            else:\n",
    "                trains[c].append(file_path)\n",
    "\n",
    "    max_trains = len(trains.items()) \\\n",
    "        if not max_train_files \\\n",
    "        else max_train_files\n",
    "\n",
    "    max_tests = len(tests.items()) \\\n",
    "        if not max_test_files \\\n",
    "        else max_test_files\n",
    "\n",
    "    datasets.append({\n",
    "        'train': {\n",
    "            c: d[:max_trains] for (c, d) in trains.items()\n",
    "        },\n",
    "        'test': {\n",
    "            c: d[:max_tests] for (c, d) in tests.items()\n",
    "        }\n",
    "    })\n",
    "\n",
    "    return datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "40c08afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_datasets(\n",
    "    data_path: str,\n",
    "    n_folds: int = 1,\n",
    "    max_train_files: int = None,\n",
    "    max_test_files: int = None,\n",
    "):\n",
    "    \"\"\"Makes the train and test datasets\n",
    "    \"\"\"\n",
    "    classes = os.listdir(data_path)\n",
    "    filenames = {\n",
    "        c: sorted(os.listdir(f\"{data_path}/{c}/\")) \n",
    "        for c in classes\n",
    "    }\n",
    "    \n",
    "    datasets = []\n",
    "    for fold in range(n_folds):\n",
    "        build_train_test_per_fold(\n",
    "            datasets=datasets,\n",
    "            classes=classes,\n",
    "            data_path=data_path,\n",
    "            filenames=filenames,\n",
    "            fold=fold,\n",
    "            max_train_files=max_train_files,\n",
    "            max_test_files=max_test_files,\n",
    "        )\n",
    "    \n",
    "    return datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "589314bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_tag_pattern(\n",
    "        condition: bool,\n",
    "        tag_pattern: list,\n",
    "        first_word: list,\n",
    "        second_word: list,\n",
    ") -> list:\n",
    "    if condition:\n",
    "        tag_pattern.append(\n",
    "            \"\".join(first_word) + \" \" + \"\".join(second_word)\n",
    "        )\n",
    "        return tag_pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b3b4c211",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def check_turney_patterns(\n",
    "        postag_1,\n",
    "        postag_2,\n",
    "        postag_3,\n",
    "):\n",
    "    patterns = []\n",
    "\n",
    "    patterns.append(\n",
    "        postag_1[1]== PennTreebank.JJ.name and\n",
    "        (postag_2[1] == PennTreebank.NN.name\n",
    "         or postag_2[1] == PennTreebank.NNS.name)\n",
    "    )\n",
    "\n",
    "    patterns.append(\n",
    "        (postag_1[1] == PennTreebank.RB.name or\n",
    "         postag_1[1] == PennTreebank.RBR.name or\n",
    "         postag_1[1] == PennTreebank.RBS.name) and\n",
    "        (postag_2[1] == PennTreebank.JJ.name and\n",
    "         postag_3[1] != PennTreebank.NN.name and\n",
    "         postag_3[1] != PennTreebank.NNS.name)\n",
    "    )\n",
    "\n",
    "    patterns.append(\n",
    "        postag_1[1] == PennTreebank.JJ.name and\n",
    "        postag_2[1] == PennTreebank.JJ.name and\n",
    "        postag_3[1] != PennTreebank.NN.name and\n",
    "        postag_3[1] != PennTreebank.NNS.name)\n",
    "\n",
    "    patterns.append(\n",
    "        (postag_1[1] == PennTreebank.NN.name or\n",
    "         postag_1[1] == PennTreebank.NNS.name) and\n",
    "        (postag_2[1] == PennTreebank.JJ.name and\n",
    "         postag_3[1] != PennTreebank.NN.name and\n",
    "         postag_3[1] != PennTreebank.NNS.name)\n",
    "    )\n",
    "\n",
    "    patterns.append(\n",
    "        (postag_1[1] == PennTreebank.RB.name or\n",
    "         postag_1[1] == PennTreebank.RBR.name or\n",
    "         postag_1[1] == PennTreebank.RBS.name) and\n",
    "        (postag_2[1] == PennTreebank.VB.name or\n",
    "         postag_2[1] == PennTreebank.VBD.name or\n",
    "         postag_2[1] == PennTreebank.VBN.name or\n",
    "         postag_2[1] == PennTreebank.VBG.name)\n",
    "    )\n",
    "\n",
    "    return any(patterns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "9079db4c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def find_pattern(postag):\n",
    "    tag_pattern = []\n",
    "    for k in range(len(postag)-2):\n",
    "        append_tag_pattern(\n",
    "            condition=check_turney_patterns(\n",
    "                postag_1=postag[k],\n",
    "                postag_2=postag[k+1],\n",
    "                postag_3=postag[k+2],\n",
    "            ),\n",
    "            tag_pattern=tag_pattern,\n",
    "            first_word=postag[k][0],\n",
    "            second_word=postag[k+1][0],\n",
    "        )\n",
    "    return tag_pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ec05de5a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def near_operator(phrase, word, text):\n",
    "    try:\n",
    "        string = word+r'\\W+(?:\\w+\\W+){0,500}?'+phrase+r'|'+phrase+r'\\W+(?:\\w+\\W+){0,500}?'+word\n",
    "        freq_phrase_near_word = (len(re.findall(string,text)))\n",
    "        return freq_phrase_near_word\n",
    "    except:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "939b1abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Turney(object):\n",
    "\n",
    "    def __init__(self, datasets, n_folds: int = 1):\n",
    "        self.datasets = datasets\n",
    "        self.pos_phrases_hits = []\n",
    "        self.neg_phrases_hits = []\n",
    "        self.pos_hits = 0.01\n",
    "        self.neg_hits = 0.01\n",
    "        self.pos_hits_init = 0.01\n",
    "        self.neg_hits_init = 0.01\n",
    "        self.accuracy = 0\n",
    "        self._positive_class = \"pos\"\n",
    "        self._negative_class = \"neg\"\n",
    "        self._classes = [self._positive_class, self._negative_class]\n",
    "        self._great_word = \"great\"\n",
    "        self._poor_word = \"poor\"\n",
    "        self.sentiments = {}\n",
    "        self.confussion_matrix = pd.DataFrame({\n",
    "                \"ActualPos\": [0,0],\n",
    "                \"ActualNeg\": [0,0],\n",
    "            }, index=[\"PredPos\", \"PredNeg\"]\n",
    "        )\n",
    "        self.n_folds = n_folds\n",
    "\n",
    "    def train(self, phrases: list, n_fold: int = 0):\n",
    "        self.pos_phrases_hits = [self.pos_hits_init] * len(phrases)\n",
    "        self.neg_phrases_hits = [self.neg_hits_init] * len(phrases)\n",
    "        self.pos_hits = self.pos_hits_init\n",
    "        self.neg_hits = self.neg_hits_init\n",
    "\n",
    "        # print(\"Callibrating the model:\")\n",
    "        for train_klass in self._classes:\n",
    "            # print(f\"Class: {train_klass}\")\n",
    "            for k, file in enumerate(self.datasets[n_fold]['train'][train_klass]):\n",
    "                # print(f\"Processing file: {k}\")\n",
    "                \n",
    "                txt_file = read_document(file)\n",
    "                for ind, phrase in enumerate(phrases):\n",
    "                    self.pos_phrases_hits[ind] += near_operator(\n",
    "                        phrase=phrase,\n",
    "                        word=self._great_word,\n",
    "                        text=txt_file\n",
    "                    )\n",
    "                    self.neg_phrases_hits[ind] += near_operator(\n",
    "                        phrase=phrase,\n",
    "                        word=self._poor_word,\n",
    "                        text=txt_file\n",
    "                    )\n",
    "                    self.pos_hits += txt_file.count(self._great_word)\n",
    "                    self.neg_hits += txt_file.count(self._poor_word)\n",
    "                \n",
    "                # print(f\"So far: pos_hits = {self.pos_hits} | neg_hits = {self.neg_hits}\")\n",
    "        \n",
    "    def evaluate(self):\n",
    "        n_fold = 0\n",
    "        for test_klass in self._classes:\n",
    "            for i, data in enumerate(self.datasets[n_fold]['test'][test_klass]):\n",
    "                print(f\"{test_klass.title()} Document: {i}\")\n",
    "                text = read_document(data)\n",
    "                doc_tokens = find_pattern(nltk.pos_tag(nltk.word_tokenize(text)))\n",
    "\n",
    "                self.train(doc_tokens)\n",
    "\n",
    "                so = self._predict_so()\n",
    "\n",
    "                is_negative = (test_klass==self._negative_class)\n",
    "                self._update_confusion_matrix(so, is_negative)\n",
    "                \n",
    "                self.sentiments.update({\n",
    "                    data: so\n",
    "                })\n",
    "                print(f\"\\tPredicted = {so} ({'pos' if so>0 else 'neg'}) | Actual = {test_klass}\")\n",
    "\n",
    "        print(\"Final Confussion Matrix\")\n",
    "        print(self.confussion_matrix)\n",
    "            \n",
    "    def _predict_so(self):\n",
    "        polarities = [\n",
    "            math.log((self.pos_phrases_hits[i] * self.neg_hits) /\n",
    "                     (self.neg_phrases_hits[i] * self.pos_hits), 2)\n",
    "            for i in range(len(self.pos_phrases_hits))\n",
    "        ]\n",
    "\n",
    "        so = sum(polarities)/len(polarities)        \n",
    "        return so\n",
    "\n",
    "    def _update_confusion_matrix(self, predict, is_negative: bool):\n",
    "        if predict > 0 and (not is_negative):\n",
    "            self.confussion_matrix.loc[\"PredPos\", \"ActualPos\"] += 1\n",
    "        if predict < 0 and is_negative:\n",
    "            self.confussion_matrix.loc[\"PredNeg\", \"ActualNeg\"] += 1\n",
    "        if predict > 0 and is_negative:\n",
    "            self.confussion_matrix.loc[\"PredPos\", \"ActualNeg\"] += 1\n",
    "        if predict < 0 and not is_negative:\n",
    "            self.confussion_matrix.loc[\"PredNeg\", \"ActualPos\"] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "f850a48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = './imdb1/'\n",
    "datasets = make_datasets(DATA_PATH, max_train_files=500, max_test_files=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac6b676",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "19a75431",
   "metadata": {},
   "outputs": [],
   "source": [
    "turney = Turney(datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "d813e597",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pos Document: 0\n",
      "\tPredicted = 2.6286907943573437 (pos) | Actual = pos\n",
      "Pos Document: 1\n",
      "\tPredicted = -1.057635406910201 (neg) | Actual = pos\n",
      "Pos Document: 2\n",
      "\tPredicted = -1.1282492532119346 (neg) | Actual = pos\n",
      "Pos Document: 3\n",
      "\tPredicted = 4.06120015223865 (pos) | Actual = pos\n",
      "Pos Document: 4\n",
      "\tPredicted = -1.419650896879345 (neg) | Actual = pos\n",
      "Pos Document: 5\n",
      "\tPredicted = 3.312462363927977 (pos) | Actual = pos\n",
      "Pos Document: 6\n",
      "\tPredicted = 1.7591797493144823 (pos) | Actual = pos\n",
      "Pos Document: 7\n",
      "\tPredicted = -0.8784895565305946 (neg) | Actual = pos\n",
      "Pos Document: 8\n",
      "\tPredicted = -1.0964236412326798 (neg) | Actual = pos\n",
      "Pos Document: 9\n",
      "\tPredicted = -1.592839664868666 (neg) | Actual = pos\n",
      "Pos Document: 10\n",
      "\tPredicted = -1.3384503029467367 (neg) | Actual = pos\n",
      "Pos Document: 11\n",
      "\tPredicted = 2.6263187774413583 (pos) | Actual = pos\n",
      "Pos Document: 12\n",
      "\tPredicted = 4.793041422477484 (pos) | Actual = pos\n",
      "Pos Document: 13\n",
      "\tPredicted = -1.0238202785200987 (neg) | Actual = pos\n",
      "Pos Document: 14\n",
      "\tPredicted = -0.4271384374691517 (neg) | Actual = pos\n",
      "Pos Document: 15\n",
      "\tPredicted = 1.3795199342443316 (pos) | Actual = pos\n",
      "Pos Document: 16\n",
      "\tPredicted = 3.1072036899259587 (pos) | Actual = pos\n",
      "Pos Document: 17\n",
      "\tPredicted = 3.6090889073903387 (pos) | Actual = pos\n",
      "Pos Document: 18\n",
      "\tPredicted = 5.130605541409799 (pos) | Actual = pos\n",
      "Pos Document: 19\n",
      "\tPredicted = 0.37473584571905105 (pos) | Actual = pos\n",
      "Neg Document: 0\n",
      "\tPredicted = -0.38955371891645135 (neg) | Actual = neg\n",
      "Neg Document: 1\n",
      "\tPredicted = -1.432491899731569 (neg) | Actual = neg\n",
      "Neg Document: 2\n",
      "\tPredicted = -5.145145379506635 (neg) | Actual = neg\n",
      "Neg Document: 3\n",
      "\tPredicted = -4.6513399436562555 (neg) | Actual = neg\n",
      "Neg Document: 4\n",
      "\tPredicted = -0.9286658234835115 (neg) | Actual = neg\n",
      "Neg Document: 5\n",
      "\tPredicted = 3.745495223446579 (pos) | Actual = neg\n",
      "Neg Document: 6\n",
      "\tPredicted = -0.5416434294853937 (neg) | Actual = neg\n",
      "Neg Document: 7\n",
      "\tPredicted = -1.0753031167362157 (neg) | Actual = neg\n",
      "Neg Document: 8\n",
      "\tPredicted = -1.3430606145197614 (neg) | Actual = neg\n",
      "Neg Document: 9\n",
      "\tPredicted = -4.098273859054212 (neg) | Actual = neg\n",
      "Neg Document: 10\n",
      "\tPredicted = -1.257502204881106 (neg) | Actual = neg\n",
      "Neg Document: 11\n",
      "\tPredicted = -1.1232871418983468 (neg) | Actual = neg\n",
      "Neg Document: 12\n",
      "\tPredicted = -1.3867450205399512 (neg) | Actual = neg\n",
      "Neg Document: 13\n",
      "\tPredicted = -4.260639070872238 (neg) | Actual = neg\n",
      "Neg Document: 14\n",
      "\tPredicted = -0.49908238224766915 (neg) | Actual = neg\n",
      "Neg Document: 15\n",
      "\tPredicted = -1.1797424423687592 (neg) | Actual = neg\n",
      "Neg Document: 16\n",
      "\tPredicted = -0.6990130137743289 (neg) | Actual = neg\n",
      "Neg Document: 17\n",
      "\tPredicted = 2.9007309098357847 (pos) | Actual = neg\n",
      "Neg Document: 18\n",
      "\tPredicted = 3.6419868731851497 (pos) | Actual = neg\n",
      "Neg Document: 19\n",
      "\tPredicted = -1.792284353582618 (neg) | Actual = neg\n",
      "Final Confussion Matrix\n",
      "         ActualPos  ActualNeg\n",
      "PredPos         11          3\n",
      "PredNeg          9         17\n"
     ]
    }
   ],
   "source": [
    "turney.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5511f15a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
