{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0bc095d",
   "metadata": {},
   "source": [
    "### Implementación del modelo en Jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844f7cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import nltk\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "from enum import Enum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27cae3bb",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "class PennTreebank(Enum):\n",
    "    CC = 1 # Coordinating conjunction\n",
    "    CD = 2 # Cardinal number\n",
    "    DT = 3 # Determiner\n",
    "    EX = 4 # Existential there\n",
    "    FW = 5 # Foreign word\n",
    "    IN = 6 # Preposition or subordinating conjunction\n",
    "    JJ = 7 # Adjective\n",
    "    JJR = 8 # Adjective, comparative\n",
    "    JJS = 9 # Adjective, superlative\n",
    "    LS = 10 # List item marker\n",
    "    MD = 11 # Modal\n",
    "    NN = 12 # Noun, singular or mass\n",
    "    NNS = 13 # Noun, plural\n",
    "    NNP = 14 # Proper noun, singular\n",
    "    NNPS = 15 # Proper noun, plural\n",
    "    PDT = 16 # Predeterminer\n",
    "    POS = 17 # Possessive ending\n",
    "    PRP = 18 # Personal pronoun\n",
    "    # PRP$ = 19 # Possessive pronoun\n",
    "    RB = 20 # Adverb\n",
    "    RBR = 21 # Adverb, comparative\n",
    "    RBS = 22 # Adverb, superlative\n",
    "    RP = 23 # Particle\n",
    "    SYM = 24 # Symbol\n",
    "    TO = 25 # to\n",
    "    UH = 26 # Interjection\n",
    "    VB = 27 # Verb, base form\n",
    "    VBD = 28 # Verb, past tense\n",
    "    VBG = 29 # Verb, gerund or present participle\n",
    "    VBN = 30 # Verb, past participle\n",
    "    VBP = 31 # Verb, non-3rd person singular present\n",
    "    VBZ = 32 # Verb, 3rd person singular present\n",
    "    WDT = 33 # Wh-determiner\n",
    "    WP = 34 # Wh-pronoun\n",
    "    # WP$ = 35 # Possessive wh-pronoun\n",
    "    WRB = 36 # Wh-adverb\n",
    "    \n",
    "\n",
    "class SentimentOrientation:\n",
    "    Positive = \"pos\"\n",
    "    Negative = \"neg\"\n",
    "\n",
    "\n",
    "class ReferenceWords:\n",
    "    highly_positive = \"great\"\n",
    "    highly_negative = \"poor\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d9801f6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def read_document(filename: str) -> str:\n",
    "    \"\"\"Reads text from file with name: filename\n",
    "    \"\"\"\n",
    "    with open(filename, \"r\", encoding=\"utf8\") as file:\n",
    "        return file.read()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2374b7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_train_test_per_fold(\n",
    "        datasets: list,\n",
    "        classes: str,\n",
    "        data_path: str,\n",
    "        filenames: list,\n",
    "        fold: int,\n",
    "        max_train_files: int = None,\n",
    "        max_test_files: int = None,\n",
    ") -> list:\n",
    "    \"\"\"Prepares the train-test split of the files to be used later\n",
    "    \"\"\"\n",
    "    trains = {c: [] for c in classes}\n",
    "    tests = {c: [] for c in classes}\n",
    "    \n",
    "    for c in classes:\n",
    "        for filename in filenames[c]:\n",
    "            file_path = f\"{data_path}/{c}/{filename}\"\n",
    "            if filename[2] == str(fold):\n",
    "                tests[c].append(file_path)\n",
    "                trains[c].append(file_path)\n",
    "            else:\n",
    "                trains[c].append(file_path)\n",
    "\n",
    "    max_trains = len(trains.items()) \\\n",
    "        if not max_train_files \\\n",
    "        else max_train_files\n",
    "\n",
    "    max_tests = len(tests.items()) \\\n",
    "        if not max_test_files \\\n",
    "        else max_test_files\n",
    "\n",
    "    datasets.append({\n",
    "        'train': {\n",
    "            c: d[:max_trains] for (c, d) in trains.items()\n",
    "        },\n",
    "        'test': {\n",
    "            c: d[:max_tests] for (c, d) in tests.items()\n",
    "        }\n",
    "    })\n",
    "\n",
    "    return datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40c08afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_datasets(\n",
    "    data_path: str,\n",
    "    n_folds: int = 1,\n",
    "    max_train_files: int = None,\n",
    "    max_test_files: int = None,\n",
    "):\n",
    "    \"\"\"Makes the train and test datasets\n",
    "    \"\"\"\n",
    "    classes = os.listdir(data_path)\n",
    "    filenames = {\n",
    "        c: sorted(os.listdir(f\"{data_path}/{c}/\")) \n",
    "        for c in classes\n",
    "    }\n",
    "    \n",
    "    datasets = []\n",
    "    for fold in range(n_folds):\n",
    "        build_train_test_per_fold(\n",
    "            datasets=datasets,\n",
    "            classes=classes,\n",
    "            data_path=data_path,\n",
    "            filenames=filenames,\n",
    "            fold=fold,\n",
    "            max_train_files=max_train_files,\n",
    "            max_test_files=max_test_files,\n",
    "        )\n",
    "    \n",
    "    return datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "589314bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_tag_pattern(\n",
    "        condition: bool,\n",
    "        tag_pattern: list,\n",
    "        first_word: list,\n",
    "        second_word: list,\n",
    ") -> list:\n",
    "    if condition:\n",
    "        tag_pattern.append(\n",
    "            \"\".join(first_word) + \" \" + \"\".join(second_word)\n",
    "        )\n",
    "        return tag_pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b3b4c211",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def check_turney_patterns(\n",
    "        postag_1,\n",
    "        postag_2,\n",
    "        postag_3,\n",
    "):\n",
    "    patterns = []\n",
    "\n",
    "    patterns.append(\n",
    "        postag_1[1] in [PennTreebank.JJ.name] and\n",
    "        (postag_2[1] in [PennTreebank.NN.name, PennTreebank.NNS.name])\n",
    "    )\n",
    "\n",
    "    patterns.append(\n",
    "        (postag_1[1] in [\n",
    "            PennTreebank.RB.name,\n",
    "            PennTreebank.RBR.name,\n",
    "            PennTreebank.RBS.name,\n",
    "            PennTreebank.JJ.name,\n",
    "            PennTreebank.NN.name,\n",
    "            PennTreebank.NNS.name,\n",
    "        ]) and (postag_2[1] in [PennTreebank.JJ.name] and\n",
    "                postag_3[1] not in [\n",
    "                            PennTreebank.NN.name,\n",
    "                            PennTreebank.NNS.name\n",
    "                        ])\n",
    "    )\n",
    "\n",
    "    patterns.append(\n",
    "        (postag_1[1] in [\n",
    "            PennTreebank.RB.name,\n",
    "            PennTreebank.RBR.name,\n",
    "            PennTreebank.RBS.name\n",
    "        ]) and (postag_2[1] in [\n",
    "            PennTreebank.VB.name,\n",
    "            PennTreebank.VBD.name,\n",
    "            PennTreebank.VBN.name,\n",
    "            PennTreebank.VBG.name\n",
    "        ])\n",
    "    )\n",
    "\n",
    "    return any(patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9079db4c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def find_pattern(postag):\n",
    "    tag_pattern = []\n",
    "    for k in range(len(postag)-2):\n",
    "        append_tag_pattern(\n",
    "            condition=check_turney_patterns(\n",
    "                postag_1=postag[k],\n",
    "                postag_2=postag[k+1],\n",
    "                postag_3=postag[k+2],\n",
    "            ),\n",
    "            tag_pattern=tag_pattern,\n",
    "            first_word=postag[k][0],\n",
    "            second_word=postag[k+1][0],\n",
    "        )\n",
    "    return tag_pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec05de5a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def near_operator(phrase, word, text):\n",
    "    try:\n",
    "        string = word+r'\\W+(?:\\w+\\W+){0,500}?'+phrase+r'|'+phrase+r'\\W+(?:\\w+\\W+){0,500}?'+word\n",
    "        freq_phrase_near_word = (len(re.findall(string,text)))\n",
    "        return freq_phrase_near_word\n",
    "    except:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "939b1abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Turney(object):\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            datasets,\n",
    "            positive_hits_init: float = 0.01,\n",
    "            negative_hits_init: float = 0.01,\n",
    "            positive_tag: str = SentimentOrientation.Positive,\n",
    "            negative_tag: str = SentimentOrientation.Negative,\n",
    "            positive_word: str = ReferenceWords.highly_positive,\n",
    "            negative_word: str = ReferenceWords.highly_negative,\n",
    "            n_folds: int = 1,\n",
    "    ):\n",
    "        self.datasets = datasets\n",
    "        self.pos_phrases_hits = []\n",
    "        self.neg_phrases_hits = []\n",
    "        self.pos_hits = positive_hits_init\n",
    "        self.neg_hits = negative_hits_init\n",
    "        self.pos_hits_init = positive_hits_init\n",
    "        self.neg_hits_init = negative_hits_init\n",
    "        self.sentiments = {}\n",
    "        self.confusion_matrix = pd.DataFrame({\n",
    "            \"ActualPos\": [0, 0],\n",
    "            \"ActualNeg\": [0, 0],\n",
    "        }, index=[\"PredPos\", \"PredNeg\"])\n",
    "\n",
    "        self._positive_tag = positive_tag\n",
    "        self._negative_tag = negative_tag\n",
    "\n",
    "        self._classes = [\n",
    "            self._positive_tag,\n",
    "            self._negative_tag\n",
    "        ]\n",
    "\n",
    "        self._positive_word = positive_word\n",
    "        self._negative_word = negative_word\n",
    "\n",
    "        self._n_folds = n_folds\n",
    "\n",
    "\n",
    "    def _compute_hits(self, phrases: list, n_fold: int = 0):\n",
    "        self.pos_phrases_hits = [self.pos_hits_init] * len(phrases)\n",
    "        self.neg_phrases_hits = [self.neg_hits_init] * len(phrases)\n",
    "        self.pos_hits = self.pos_hits_init\n",
    "        self.neg_hits = self.neg_hits_init\n",
    "\n",
    "        for train_klass in self._classes:\n",
    "            for k, file in enumerate(self.datasets[n_fold]['train'][train_klass]):\n",
    "                txt_file = read_document(file)\n",
    "                for ind, phrase in enumerate(phrases):\n",
    "                    self.pos_phrases_hits[ind] += near_operator(\n",
    "                        phrase=phrase,\n",
    "                        word=self._positive_word,\n",
    "                        text=txt_file\n",
    "                    )\n",
    "                    self.neg_phrases_hits[ind] += near_operator(\n",
    "                        phrase=phrase,\n",
    "                        word=self._negative_word,\n",
    "                        text=txt_file\n",
    "                    )\n",
    "                    self.pos_hits += txt_file.count(self._positive_word)\n",
    "                    self.neg_hits += txt_file.count(self._negative_word)\n",
    "\n",
    "\n",
    "    def evaluate(self):\n",
    "        n_fold = 0\n",
    "        for test_klass in self._classes:\n",
    "            for i, data in enumerate(self.datasets[n_fold]['test'][test_klass]):\n",
    "                print(f\"{test_klass.title()} Document: {i}\")\n",
    "                text = read_document(data)\n",
    "\n",
    "                doc_tokens = find_pattern(\n",
    "                    postag=nltk.pos_tag(nltk.word_tokenize(text))\n",
    "                )\n",
    "\n",
    "                self._compute_hits(doc_tokens)\n",
    "\n",
    "                so = self.compute_sentiment_orientation()\n",
    "\n",
    "                is_negative = (test_klass == self._negative_tag)\n",
    "                self._update_confusion_matrix(\n",
    "                    predict=so,\n",
    "                    is_negative=is_negative\n",
    "                )\n",
    "\n",
    "                self.sentiments.update({\n",
    "                    data: so\n",
    "                })\n",
    "                print(f\"\\tPredicted = {so} ({'pos' if so > 0 else 'neg'}) |\"\n",
    "                      f\" Actual = {test_klass}\")\n",
    "\n",
    "        print(\"Final Confusion Matrix\")\n",
    "        print(self.confusion_matrix)\n",
    "\n",
    "    def compute_sentiment_orientation(self):\n",
    "        polarities = [\n",
    "            math.log((self.pos_phrases_hits[i] * self.neg_hits) /\n",
    "                     (self.neg_phrases_hits[i] * self.pos_hits), 2)\n",
    "            for i in range(len(self.pos_phrases_hits))\n",
    "        ]\n",
    "\n",
    "        so = sum(polarities) / len(polarities)\n",
    "        return so\n",
    "\n",
    "    def _update_confusion_matrix(self, predict, is_negative: bool):\n",
    "        if predict > 0 and (not is_negative):\n",
    "            self.confusion_matrix.loc[\"PredPos\", \"ActualPos\"] += 1\n",
    "        if predict < 0 and is_negative:\n",
    "            self.confusion_matrix.loc[\"PredNeg\", \"ActualNeg\"] += 1\n",
    "        if predict > 0 and is_negative:\n",
    "            self.confusion_matrix.loc[\"PredPos\", \"ActualNeg\"] += 1\n",
    "        if predict < 0 and not is_negative:\n",
    "            self.confusion_matrix.loc[\"PredNeg\", \"ActualPos\"] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f850a48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = './imdb1/'\n",
    "datasets = make_datasets(DATA_PATH, max_train_files=50, max_test_files=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "19a75431",
   "metadata": {},
   "outputs": [],
   "source": [
    "turney = Turney(datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d813e597",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pos Document: 0\n",
      "\tPredicted = 2.391695804722235 (pos) | Actual = pos\n",
      "Pos Document: 1\n",
      "\tPredicted = -1.9531303620724338 (neg) | Actual = pos\n",
      "Pos Document: 2\n",
      "\tPredicted = -1.672596233908496 (neg) | Actual = pos\n",
      "Pos Document: 3\n",
      "\tPredicted = 4.299289771801991 (pos) | Actual = pos\n",
      "Pos Document: 4\n",
      "\tPredicted = -1.8568933667804264 (neg) | Actual = pos\n",
      "Pos Document: 5\n",
      "\tPredicted = 3.0364602496118254 (pos) | Actual = pos\n",
      "Pos Document: 6\n",
      "\tPredicted = 1.7474129417510944 (pos) | Actual = pos\n",
      "Pos Document: 7\n",
      "\tPredicted = -1.5176594270011527 (neg) | Actual = pos\n",
      "Pos Document: 8\n",
      "\tPredicted = -1.530040801547207 (neg) | Actual = pos\n",
      "Pos Document: 9\n",
      "\tPredicted = -2.398518118151481 (neg) | Actual = pos\n",
      "Neg Document: 0\n",
      "\tPredicted = -1.991924745700809 (neg) | Actual = neg\n",
      "Neg Document: 1\n",
      "\tPredicted = -1.2222673858552913 (neg) | Actual = neg\n",
      "Neg Document: 2\n",
      "\tPredicted = -7.034449839554492 (neg) | Actual = neg\n",
      "Neg Document: 3\n",
      "\tPredicted = -6.3871110378333675 (neg) | Actual = neg\n",
      "Neg Document: 4\n",
      "\tPredicted = -1.8854278186568987 (neg) | Actual = neg\n",
      "Neg Document: 5\n",
      "\tPredicted = 3.7024616043106455 (pos) | Actual = neg\n",
      "Neg Document: 6\n",
      "\tPredicted = -2.3743078400309567 (neg) | Actual = neg\n",
      "Neg Document: 7\n",
      "\tPredicted = -1.9783004093674499 (neg) | Actual = neg\n",
      "Neg Document: 8\n",
      "\tPredicted = -2.1385838963557675 (neg) | Actual = neg\n",
      "Neg Document: 9\n",
      "\tPredicted = -6.44905078264959 (neg) | Actual = neg\n",
      "Final Confusion Matrix\n",
      "         ActualPos  ActualNeg\n",
      "PredPos          4          1\n",
      "PredNeg          6          9\n"
     ]
    }
   ],
   "source": [
    "turney.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e77cd6e9",
   "metadata": {},
   "source": [
    "## Utilización de la libreria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "74b674f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentiment_miner.turney import prepare_datasets, Turney"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1d9467d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = './imdb1/'\n",
    "datasets = prepare_datasets(DATA_PATH, max_train_files=50, max_test_files=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cda3c87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "turney_lib = Turney(datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "72648d22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pos Document: 0\n",
      "\tPredicted = 2.391695804722235 (pos) | Actual = pos\n",
      "Pos Document: 1\n",
      "\tPredicted = -1.9531303620724338 (neg) | Actual = pos\n",
      "Pos Document: 2\n",
      "\tPredicted = -1.672596233908496 (neg) | Actual = pos\n",
      "Pos Document: 3\n",
      "\tPredicted = 4.299289771801991 (pos) | Actual = pos\n",
      "Pos Document: 4\n",
      "\tPredicted = -1.8568933667804264 (neg) | Actual = pos\n",
      "Pos Document: 5\n",
      "\tPredicted = 3.0364602496118254 (pos) | Actual = pos\n",
      "Pos Document: 6\n",
      "\tPredicted = 1.7474129417510944 (pos) | Actual = pos\n",
      "Pos Document: 7\n",
      "\tPredicted = -1.5176594270011527 (neg) | Actual = pos\n",
      "Pos Document: 8\n",
      "\tPredicted = -1.530040801547207 (neg) | Actual = pos\n",
      "Pos Document: 9\n",
      "\tPredicted = -2.398518118151481 (neg) | Actual = pos\n",
      "Neg Document: 0\n",
      "\tPredicted = -1.991924745700809 (neg) | Actual = neg\n",
      "Neg Document: 1\n",
      "\tPredicted = -1.2222673858552913 (neg) | Actual = neg\n",
      "Neg Document: 2\n",
      "\tPredicted = -7.034449839554492 (neg) | Actual = neg\n",
      "Neg Document: 3\n",
      "\tPredicted = -6.3871110378333675 (neg) | Actual = neg\n",
      "Neg Document: 4\n",
      "\tPredicted = -1.8854278186568987 (neg) | Actual = neg\n",
      "Neg Document: 5\n",
      "\tPredicted = 3.7024616043106455 (pos) | Actual = neg\n",
      "Neg Document: 6\n",
      "\tPredicted = -2.3743078400309567 (neg) | Actual = neg\n",
      "Neg Document: 7\n",
      "\tPredicted = -1.9783004093674499 (neg) | Actual = neg\n",
      "Neg Document: 8\n",
      "\tPredicted = -2.1385838963557675 (neg) | Actual = neg\n",
      "Neg Document: 9\n",
      "\tPredicted = -6.44905078264959 (neg) | Actual = neg\n",
      "Final Confusion Matrix\n",
      "         ActualPos  ActualNeg\n",
      "PredPos          4          1\n",
      "PredNeg          6          9\n"
     ]
    }
   ],
   "source": [
    "turney_lib.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392d56a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}